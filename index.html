<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <link
      rel="stylesheet"
      type="text/css"
      href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css"
    />
    <title>Bad UI Battle - Phone input via musical notes</title>
  </head>
  <body style="background-color:  #000000!important;">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/essentia.js@0.1.0/dist/essentia-wasm.web.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/essentia.js@0.1.0/dist/essentia-wasm.web.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/essentia.js@0.1.0/dist/essentia.js-extractor.js"></script>
   
    <div class="ui main_wrapper landing-image">
      <div class="ui header centered" id="header">


      <div class="ui divider" style="height: 5px; width: 2px;"></div>
        
      <div class="body-container">
        <div class="ui centered one column grid container">
          <div class="ui vertical buttons row">
            <center>
              <h1 style="color:#FFF;">Please enter your phone number</h1>
              <button
                id="recordButton"
                class="ui red inverted big button record-button"
              >
                Enable Microphone &nbsp;&nbsp;<i class="microphone icon"></i>
              </button>
              
            </center>
          </div>
        </div>
        <hr>
        <input type="tel" id="phone" width="300px" height="40px" hidden="true">
        <input type="tel" id="phone_visible" readonly="true" width="300px" height="40px">
        <div style="color:#FFF;text-align:left; padding-left: 10px;">Play the following musical notes to enter your telephone number: </div>
        <ul style="color:#FFF;text-align:left">
          <li>C: &nbsp; &nbsp; 0</li>
          <li>C#:&nbsp; 1</li>
          <li>D: &nbsp; &nbsp; 2</li>
          <li>D#:&nbsp; 3</li>
          <li>E: &nbsp; &nbsp; 4</li>
          <li>F: &nbsp; &nbsp; 5</li>
          <li>F#:&nbsp; 6</li>
          <li>G: &nbsp; &nbsp; 7</li>
          <li>G#:&nbsp; 8</li>
          <li>A: &nbsp; &nbsp; 9</li>
          <li>A#:&nbsp; Delete</li>
          <li>B: &nbsp; &nbsp; -</li>
        </ul>
        <hr>
        <center>
          <h3 style="color:#FFF;">Created by <a href="https://www.github.com/nickvellios">Nick Vellios</a> with the help of <a href="https://mtg.github.io/essentia.js/">essentia.js.</a></h3>
        </center>
      </div>
      </div>
      <script>
        const KEYS = [ 'A', 'A#', 'B', 'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#'];

        const PITCH_CLASS_NUMERAL = {
            'C': '0', 
            'C#': '1', 
            'D': '2', 
            'D#': '3', 
            'E': '4', 
            'F': '5', 
            'F#': '6', 
            'G': '7', 
            'G#': '8', 
            'A': '9', 
            'A#': 'DEL', 
            'B': '-'
        };

        const PITCH_CLASS_CHARCODE = {
            'C': 49, 
            'C#': 49, 
            'D': 50, 
            'D#': 51,
            'E': 52,
            'F': 53,
            'F#': 54,
            'G': 55,
            'G#': 56,
            'A': 57,
            'A#': 8,
            'B': '-'
        };
        // global var to load essentia.js core instance
        let essentiaExtractor;
        let isEssentiaInstance = false;
        // global var for web audio API AudioContext
        let audioCtx;
        // buffer size microphone stream (bufferSize is high in order to make PitchYinProbabilistic algo to work)
        let bufferSize = 8192;
        let hopSize = 2048;

        let mic, scriptNode, gain;

        try {
          const AudioContext = window.AudioContext || window.webkitAudioContext;
          audioCtx = new AudioContext();
        } catch (e) {
          throw "Could not instantiate AudioContext: " + e.message;
        }

        // global var getUserMedia mic stream
        let gumStream;

        // record native microphone input and do further audio processing on each audio buffer using the given callback functions
        function startMicRecordStream(
          audioCtx,
          bufferSize,
          onProcessCallback,
          btnCallback
        ) {
          // cross-browser support for getUserMedia
          navigator.getUserMedia =
            navigator.getUserMedia ||
            navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia ||
            navigator.msGetUserMedia;
          window.URL =
            window.URL || window.webkitURL || window.mozURL || window.msURL;

          if (navigator.getUserMedia) {
            console.log("Initializing audio...");
            navigator.getUserMedia(
              { audio: true, video: false },
              function(stream) {
                gumStream = stream;
                if (gumStream.active) {
                  console.log(
                    "Audio context sample rate = " + audioCtx.sampleRate
                  );
                  mic = audioCtx.createMediaStreamSource(stream);
                  // We need the buffer size that is a power of two
                  if (bufferSize % 2 != 0 || bufferSize < 4096) {
                    throw "Choose a buffer size that is a power of two and greater than 4096";
                  }
                  // In most platforms where the sample rate is 44.1 kHz or 48 kHz,
                  // and the default bufferSize will be 4096, giving 10-12 updates/sec.
                  console.log("Buffer size = " + bufferSize);
                  if (audioCtx.state == "suspended") {
                    audioCtx.resume();
                  }
                  scriptNode = audioCtx.createScriptProcessor(bufferSize, 1, 1);
                  // onprocess callback (here we can use essentia.js algos)
                  scriptNode.onaudioprocess = onProcessCallback;
                  // It seems necessary to connect the stream to a sink for the pipeline to work, contrary to documentataions.
                  // As a workaround, here we create a gain node with zero gain, and connect temp to the system audio output.
                  gain = audioCtx.createGain();
                  gain.gain.setValueAtTime(0, audioCtx.currentTime);
                  mic.connect(scriptNode);
                  scriptNode.connect(gain);
                  gain.connect(audioCtx.destination);

                  if (btnCallback) {
                    btnCallback();
                  }
                } else {
                  throw "Mic stream not active";
                }
              },
              function(message) {
                throw "Could not access microphone - " + message;
              }
            );
          } else {
            throw "Could not access microphone - getUserMedia not available";
          }
        }

        function stopMicRecordStream() {
          console.log("Stopped recording ...");
          // stop mic stream
          gumStream.getAudioTracks().forEach(function(track) {
            track.stop();
          });
          $("#recordButton").removeClass("recording");
          $("#recordButton").html(
            'Enable Microphone &nbsp;&nbsp;<i class="microphone icon"></i>'
          );
          audioCtx.suspend().then(() => {
            mic.disconnect();
            gain.disconnect();
            scriptNode.disconnect();

            mic, gain, scriptNode = null;
          });
        }

        // ScriptNodeProcessor callback function to extract pitchyin feature using essentia.js and plotting it on the front-end
        function onRecordEssentiaFeatureExtractor(event) {
          const input = document.getElementById('phone');
          const input_visible = document.getElementById('phone_visible');
          input.focus();
          // input.select();
          let audioBuffer = event.inputBuffer.getChannelData(0);

          // compute RMS for thresholding:
          const rms = essentiaExtractor.RMS(essentiaExtractor.arrayToVector(audioBuffer)).rms;

          if (rms >= 0.12) {
            // compute hpcp for overlapping frames of audio
            const hpcp = essentiaExtractor.hpcpExtractor(audioBuffer);
            // console.log(`raw: ${hpcp}`);

            const scaledHPCP = hpcp.map(i => 100* Math.tanh(Math.pow(i*0.5, 2)));
            
            let detectedNotes = KEYS.map((k, i) => 25+scaledHPCP[i]/3);

            var result = detectedNotes.reduce(function (previousValue, currentValue, index, array) {
              if(previousValue.value > currentValue) {
                return previousValue;
              } else {
                return {value: currentValue, index: index};
              }
            })

            if (PITCH_CLASS_CHARCODE[KEYS[result.index]] == 8) {
              let input_val = input.value;
              input_val.substring(0, input_val.length - 1);
              input.value = input_val.substring(0, input_val.length - 1);
            } else {
              input.value += PITCH_CLASS_NUMERAL[KEYS[result.index]];
            }
            input_visible.value = input.value;
            console.log(PITCH_CLASS_CHARCODE[KEYS[result.index]]);
            console.log(KEYS[result.index]);
          }
        }

        $(document).ready(function() {
          // add event listeners to ui objects
          $("#recordButton").click(function() {
            let recording = $(this).hasClass("recording");
            if (!recording) {
              $(this).prop("disabled", true);

              // loads the WASM backend and runs the feature extraction
              EssentiaWASM().then(function(essentiaWasmModule) {
                if (!isEssentiaInstance) {
                  essentiaExtractor = new EssentiaExtractor(essentiaWasmModule);
                  // settings specific to an algorithm
                  // essentiaExtractor.profile.HPCP.nonLinear = true;
                            // modifying default extractor settings
                  essentiaExtractor.frameSize = bufferSize;
                  essentiaExtractor.hopSize = hopSize;
                  essentiaExtractor.sampleRate = audioCtx.sampleRate;
                  essentiaExtractor.profile.HPCP.normalized = 'none';
                  essentiaExtractor.profile.HPCP.harmonics = 0;
                  console.log('profile changed')
                  isEssentiaInstance = true;
                }
                // start microphone stream using getUserMedia
                startMicRecordStream(
                  audioCtx,
                  bufferSize,
                  onRecordEssentiaFeatureExtractor, // essentia.js feature extractor callback function
                  function() {
                    // called when the promise fulfilled
                    $("#recordButton").addClass("recording");
                    $("#recordButton").html(
                      'Stop &nbsp;&nbsp;<i class="stop icon"></i>'
                    );
                    $("#recordButton").prop("disabled", false);
                  }
                );
              });
            } else {
              stopMicRecordStream();
            }
          }); // end recordButton onClick
        });
      </script>
    </div>
  </body>
</html>
